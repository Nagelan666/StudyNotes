# 1 缓存

## 1.1 本地缓存和分布式缓存区别

**本地缓存**：本地缓存会占用堆内存，影响垃圾回收、影响系统性能。适用于数据不经常变动，但访问频次高，应用又耗时敏感的场景。但是本地缓存需要自己实现很多功能，如果实现的不好可能导致线程安全问题还有OOM问题。



**分布式缓存**：分布式缓存两大开销会导致其慢于本地缓存，网络延迟和对象序列化



## 1.2 如何设计本地缓存

### 1.2.1 数据结构

本地缓存最常见的是直接使用 Map 来存储，比如 guava 使用 ConcurrentHashMap，ehcache 也是用了 ConcurrentHashMap，Mybatis 二级缓存使用 HashMap 来存储：

```java
Map<Object, Object> cache = new ConcurrentHashMap<Object, Object>()
```

Mybatis 使用 HashMap 本身是非线程安全的，所以可以看到起内部使用了一个 SynchronizedCache 用来包装，保证线程的安全性；
 当然除了使用 Map 来存储，可能还使用其他数据结构来存储，比如 redis 使用了双端链表，压缩列表，整数集合，跳跃表和字典；当然这主要是因为 redis 对外提供的接口很丰富除了哈希还有列表，集合，有序集合等功能；



### 1.2.2 对象上限

本地缓存常见的一个属性，一般缓存都会有一个默认值比如 1024，在用户没有指定的情况下默认指定；当缓存的数据达到指定最大值时，需要有相关策略从缓存中清除多余的数据这就涉及到下面要介绍的清除策略；



### 1.2.3 清除策略

配合对象上限之后使用，场景的清除策略如：LRU(最近最少使用)、FIFO(先进先出)、LFU(最近最不常用)、SOFT(软引用)、WEAK(弱引用)；

1. **LRU**：Least Recently Used 的缩写最近最少使用，移除最长时间不被使用的对象；常见的使用 LinkedHashMap 来实现，也是很多本地缓存默认使用的策略；

2. **FIFO**：先进先出，按对象进入缓存的顺序来移除它们；常见使用队列 Queue 来实现；

3. **LFU**：Least Frequently Used 的缩写大概也是最近最少使用的意思，和 LRU 有点像；区别点在 LRU 的淘汰规则是基于访问时间，而 LFU 是基于访问次数的；可以通过 HashMap 并且记录访问次数来实现；

4. **SOFT**：软引用基于垃圾回收器状态和软引用规则移除对象；常见使用 SoftReference 来实现；

5. **WEAK**：弱引用更积极地基于垃圾收集器状态和弱引用规则移除对象；常见使用 WeakReference 来实现；

   



### 1.2.4 过期时间

设置过期时间，让缓存数据在指定时间过后自动删除；常见的过期数据删除策略有两种方式：被动删除和主动删除；
**被动删除**：每次进行 get/put 操作的时候都会检查一下当前 key 是否已经过期，如果过期则删除，类似如下代码：

```java
if (System.currentTimeMillis() - lastClear > clearInterval) {
      clear();
}
```



**主动删除**：专门有一个 job 在后台定期去检查数据是否过期，如果过期则删除，这其实可以有效的处理冷数据；





### 1.2.5 线程安全

尽量用线程安全的类去存储数据，比如使用 ConcurrentHashMap 代替 HashMap；或者提供相应的同步处理类，比如 Mybatis 提供了 SynchronizedCache：

```java
public synchronized void putObject(Object key, Object object) {
    ...省略...
  }

  @Override
  public synchronized Object getObject(Object key) {
    ...省略...
  }
```



### 1.2.6 **6. 简明的接口**

提供常用的 get，put，remove，clear，getSize 方法即可，比如 Mybatis 的 Cache 接口：

```java
public interface Cache {
  String getId();
  void putObject(Object key, Object value);
  Object getObject(Object key);
  Object removeObject(Object key);
  void clear();
  int getSize();
  ReadWriteLock getReadWriteLock();
}
```



再来看看 guava 提供的 Cache 接口，相对来说也是比较简洁的：

```java
public interface Cache<K, V> {
  V getIfPresent(@CompatibleWith("K") Object key);
  V get(K key, Callable<? extends V> loader) throws ExecutionException;
  ImmutableMap<K, V> getAllPresent(Iterable<?> keys);
  void put(K key, V value);
  void putAll(Map<? extends K, ? extends V> m);
  void invalidate(@CompatibleWith("K") Object key);
  void invalidateAll(Iterable<?> keys);
  void invalidateAll();
  long size();
  CacheStats stats();
  ConcurrentMap<K, V> asMap();
  void cleanUp();
}
```



### 1.2.7 是否持久化

持久化的好处是重启之后可以再次加载文件中的数据，这样就起到类似热加载的功效；比如redis提供了 AOF 和 RDB 两种持久化方式；当然很多情况下可以配合使用两种方式；



### 1.2.8 阻塞机制

除了在 Mybatis 中看到了 BlockingCache 来实现此功能，之前在看的时候其中有实现一个很完美的缓存，大致代码如下：

```java
public class Memoizerl<A, V> implements Computable<A, V> {
    private final Map<A, Future<V>> cache = new ConcurrentHashMap<A, Future<V>>();
    private final Computable<A, V> c;

    public Memoizerl(Computable<A, V> c) {
        this.c = c;
    }

    @Override
    public V compute(A arg) throws InterruptedException, ExecutionException {
        while (true) {
            Future<V> f = cache.get(arg);
            if (f == null) {
                Callable<V> eval = new Callable<V>() {
                    @Override
                    public V call() throws Exception {
                        return c.compute(arg);
                    }
                };
                FutureTask<V> ft = new FutureTask<V>(eval);
                f = cache.putIfAbsent(arg, ft);
                if (f == null) {
                    f = ft;
                    ft.run();
                }
                try {
                    return f.get();
                } catch (CancellationException e) {
                    cache.remove(arg, f);
                }
            }
        }
    }
}
```

compute  是一个计算很费时的方法，所以这里把计算的结果缓存起来，但是有个问题就是如果两个线程同时进入此方法中怎么保证只计算一次，这里最核心的地方在于使用了  ConcurrentHashMap 的 putIfAbsent 方法，同时只会写入一个 FutureTask； 





# 2 如何保证缓存和数据库的数据一致性

只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题

那么，如何解决一致性问题？

一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案。它会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上请求。



## 2.1 Cache Aside Pattern

最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，先删除缓存，再更新数据库



### 2.1.1 **更新的时候为什么是删除缓存，而不是更新缓存？**

1. 在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。
2. **lazy 计算**的思想，让它到需要被使用的时候再重新计算。因为更新缓存的代价有时候是很高的，如果频繁修改一个缓存涉及的多个表，缓存也频繁更新，但是缓存并不一定会被读到，这样浪费了资源。像 mybatis，hibernate，都有懒加载思想。





### 2.1.2 为什么更新的时候，先删除缓存，再更新数据库？

> 问题：先修改数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。

**解决思路**：先删除缓存，再修改数据库。如果数据库修改失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。

解决了最初级的数据不一致问题。



### 2.1.3 **比较复杂的数据不一致问题分析**

> 问题：数据发生了变更，先删除了缓存，然后要去修改数据库，还没来得及修改，一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据库的修改。

高并发场景下，会很容易出现这样的问题。



**解决方案如下：**

为解决其缺陷，添加队列，凡是遇到写请求，则将写请求放入队列中，由队列对写请求统一管理，写请求处理成功，则从队列中删除。当有一个读请求过来时，到队列查询，是否有对应的写请求，如果有则放入队列中，等待写请求执行完之后再执行读请求。这样使得请求遵循了FIFO，也就解决了数据不一致的问题。



高并发的场景下，该解决方案要注意的问题：



**1.读请求长时阻塞**

倘若访问量大，处理器来不及处理，队列内的请求数量越来越高，则会影响查询效率。出现这种情况，就要进行压力测试，加机器集群执行，帮忙分担压力，为防止某个请求阻塞情况，也可为其设置超时机制或者过期机制。



**2、读请求并发量过高**

这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。

但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。



**3、多服务实例部署的请求路由**

可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器路由到相同的服务实例上。

比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。



**4、热点商品的路由问题，导致请求的倾斜**

万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。



 

#  :cloud:待写

五种IO模型的区别  

select、poll、epoll的区别？    