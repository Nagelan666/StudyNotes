# 1 进程与线程的区别

1. 进程是资源的分配和调度的一个独立单元，而线程是CPU调度的基本单元
2. 同一个进程中可以包括多个线程，并且线程共享整个进程的资源（寄存器、堆栈、上下文），一个进行至少包3.进程的创建调用fork或者vfork，而线程的创建调用pthread_create，进程结束后它拥有的所有线程都将销毁，而线程的结束不会影响同个进程中的其他线程的结束
3. 线程是轻两级的进程，它的创建和销毁所需要的时间比进程小很多，所有操作系统中的执行功能都是创建线程去完成的
4. 线程中执行时一般都要进行同步和互斥，因为他们共享同一进程的所有资源
5. 线程有自己的私有属性TCB，线程id，寄存器、硬件上下文，而进程也有自己的私有属性进程控制块PCB，这些私有属性是不被共享的，用来标示一个进程或一个线程的标志



**共享的资源有：**

1. 堆：由于堆是在进程空间中开辟出来的，所以它是理所当然地被共享的；因此new出来的都是共享的（16位平台上分全局堆和局部堆，局部堆是独享的）

2. 全局变量 它是与具体某一函数无关的，所以也与特定线程无关；因此也是共享的
3. 静态变量 虽然对于局部变量来说，它在代码中是“放”在某一函数中的，但是其存放位置和全局变量一样，存于堆中开辟的.bss和.data段，是共享的
4. 文件等公用资源  这个是共享的，使用这些公共资源的线程必须同步。Win32 提供了几种同步资源的方式，包括信号、临界区、事件和互斥体。

**独享的资源有：**

1. 栈：栈是独享的
2. 寄存器 ：这个可能会误解，因为电脑的寄存器是物理的，每个线程去取值难道不一样吗？其实线程里存放的是副本，包括程序计数器PC





# 2 fork

[博客1](https://blog.csdn.net/jason314/article/details/5640969)

[博客2](https://www.jianshu.com/p/1327c51a4a99)

一个进程，包括代码、数据和分配给进程的资源。fork（）函数通过系统调用创建一个与原来进程几乎完全相同的进程，也就是两个进程可以做完全相同的事，但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。 

一个进程调用fork（）函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后把原来的进程的所有值都复制到新的新进程中，只有少数值与原来的进程的值不同。相当于克隆了一个自己。

### 2.1 示例1

```c
/*
 *  fork_test.c
 *  version 1
 *  Created on: 2010-5-29
 *      Author: wangth
 */
#include <unistd.h>
#include <stdio.h> 
int main () 
{ 
	pid_t fpid; //fpid表示fork函数返回的值
	int count=0;
	fpid=fork(); 
	if (fpid < 0) 
		printf("error in fork!"); 
	else if (fpid == 0) {
		printf("i am the child process, my process id is %d/n",getpid()); 
		count++;
	}
	else {
		printf("i am the parent process, my process id is %d/n",getpid()); 
		count++;
	}
	printf("统计结果是: %d/n",count);
	return 0;
}
```



运行结果：

```
 i am the child process, my process id is 5574
 统计结果是: 1
 i am the parent process, my process id is 5573
 统计结果是: 1
```



![](./assets/1.1.png)

> 可以看到，这里代码的复制是从if(fpid<0)开始的，而不是#include <unistd.h>

这两个进程的变量都是独立的，存在不同的地址中，不是共用的，这点要注意。可以说，我们就是**通过fpid来识别和操作父子进程的。**

每个进程都有一个独特（互不相同）的进程标识符（process ID），可以通过getpid（）函数获得，还有一个记录父进程pid的变量，可以通过getppid（）函数获得变量的值。 

**fpid可能有三种不同的返回值：**
    1）在父进程中，fork返回新创建子进程的进程ID；
    2）在子进程中，fork返回0；
    3）如果出现错误，fork返回一个负值；

其实就相当于链表，进程形成了链表，父进程的fpid(p 意味point)指向子进程的进程id, 因为子进程没有子进程，所以其fpid为0. 



**fork出错可能有两种原因：**     

1）当前的进程数已经达到了系统规定的上限，这时errno的值被设置为EAGAIN。    

2）系统内存不足，这时errno的值被设置为ENOMEM。 



> 创建新进程成功后，系统中出现两个基本完全相同的进程，这两个进程执行没有固定的先后顺序，哪个进程先执行要看系统的进程调度策略。 





### 2.2 示例2

```c
/*
 *  fork_test.c
 *  version 2
 *  Created on: 2010-5-29
 *      Author: wangth
 */
#include <unistd.h>
#include <stdio.h>
int main(void)
{
   int i=0;
   printf("start/n");
   //ppid指当前进程的父进程pid
   //pid指当前进程的pid,
   //fpid指fork返回给当前进程的值
   for(i=0;i<2;i++){
       pid_t fpid=fork();
       if(fpid==0)
    	   printf("%d child  %4d %4d %4d/n",i,getppid(),getpid(),fpid);
       else
    	   printf("%d parent %4d %4d %4d/n",i,getppid(),getpid(),fpid);
   }
   return 0;
}
```


输出结果：

```c
	start
  //i    getppid(),getpid(),fpid
    0 parent 2043 3224 3225
    0 child  3224 3225    0
    1 parent 2043 3224 3226
    1 parent 3224 3225 3227
    1 child     1 3227    0
    1 child     1 3226    0 
```



![](./assets/1.2.png)



p3226，p3227的父进程难道不该是p3224和p3225吗，怎么会是1呢？这里得讲到进程的创建和死亡的过程，在p3224和p3225执行完第二个循环后，main函数就该退出了，也即进程该死亡了，因为它已经做完所有事情了。p3224和p3225死亡后，p3226，p3227就没有父进程了，这在操作系统是不被允许的，所以p3226，p3227的父进程就被置为p1了，p1是永远不会死亡的.

> 这个程序最终产生了3个子进程，执行过6次printf（）函数。 



p2043是main函数的进程。①②③④这些数字表示进程执行的顺序。

​		  ①		②

p2043->p3224->p3225  

​		   ③		 ④

​		   ↓             ↓

​		p3226   p3227

​		    ⑤	  ⑥



### 2.3 示例3

```c
/*
 *  fork_test.c
 *  version 3
 *  Created on: 2010-5-29
 *      Author: wangth
 */
#include <unistd.h>
#include <stdio.h>
int main(void)
{
   int i=0;
   for(i=0;i<3;i++){
       pid_t fpid=fork();
       if(fpid==0)
    	   printf("son/n");
       else
    	   printf("father/n");
   }
   return 0;

}
```



```
    father
    son
    father
    father
    father
    father
    son
    son
    father
    son
    son
    son
    father
    son 
```

分析：

 for        i=0          1                 2
              father     father     father
                                              son
                                son       father
                                              son
               son        father     father
                                             son
                              son        father
                                            son


### 2.4 示例4

```java
/*
 *  fork_test.c
 *  version 4
 *  Created on: 2010-5-29
 *      Author: wangth
 */
#include <unistd.h>
#include <stdio.h>
int main() {
	pid_t fpid;//fpid表示fork函数返回的值
	//printf("fork!");
	printf("fork!/n");
	fpid = fork();
	if (fpid < 0)
		printf("error in fork!");
	else if (fpid == 0)
		printf("I am the child process, my process id is %d/n", getpid());
	else
		printf("I am the parent process, my process id is %d/n", getpid());
	return 0;
}
```



 执行结果如下：

```
 fork!
I am the parent process, my process id is 3361
I am the child process, my process id is 3362 
```


 如果把语句printf("fork!/n");注释掉，执行printf("fork!");

   则新的程序的执行结果是：

```
fork!I am the parent process, my process id is 3298
fork!I am the child process, my process id is 3299 
```

就跟printf的缓冲机制有关了，printf某些内容时，操作系统仅仅是把该内容放到了stdout的缓冲队列里了,并没有实际的写到屏幕上。但是,只要看到有/n 则会立即刷新stdout,因此就马上能够打印了。

- 运行了printf("fork!")后,“fork!”仅仅被放到了缓冲里,程序运行到fork时缓冲里面的“fork!”  被子进程复制过去了。
-  而运行printf("fork! /n")后,“fork!”被立即打印到了屏幕上。



### 2.5 示例5

```c
#include <stdio.h>
int main(int argc, char* argv[])
{
   fork();
   fork() && fork() || fork();
   fork();
   printf("+/n");
}

```



# 3 进程间的通信方式（IPC）

> InterProcess Communication 

### 2.1 管道

管道，通常指无名管道，是 UNIX 系统IPC最古老的形式。
**特点：**

它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端。

它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）。

它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

```c
#include <unistd.h>
int pipe(int fd[2]);    // 返回值：若成功返回0，失败返回-1
```

当一个管道建立时，它会创建两个文件描述符：`fd[0]`为读而打开，`fd[1]`为写而打开。如下图： 

![](./assets/1.3.png)

要关闭管道只需将这两个文件描述符关闭即可。 



 **例子**

单个进程中的管道几乎没有任何用处。所以，通常调用 pipe 的进程接着调用 fork，这样就创建了父进程与子进程之间的 IPC 通道。如下图所示： 

![](./assets/1.4.png)

若要数据流从父进程流向子进程，则关闭父进程的读端（`fd[0]`）与子进程的写端（`fd[1]`）；反之，则可以使数据流从子进程流向父进程。 

```c
#include<stdio.h>
#include<unistd.h>
 
int main()
{
     int fd[2];  // 两个文件描述符
     pid_t pid;
     char buff[20];
 
     if(pipe(fd) < 0)  // 创建管道
         printf("Create Pipe Error!\n");
 
     if((pid = fork()) < 0)  // 创建子进程
         printf("Fork Error!\n");
     else if(pid > 0)  // 父进程
     {
         close(fd[0]); // 关闭读端
         write(fd[1], "hello world\n", 12);
     }
     else
     {         
         close(fd[1]); // 关闭写端
         read(fd[0], buff, 20);
         printf("%s", buff);
     } 
    return 0;
}


```



### 2.2 FIFO

FIFO，也称为命名管道，它是一种文件类型。

**特点:**

1. FIFO可以在无关的进程之间交换数据，与无名管道不同。
2. FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。





FIFO的通信方式类似于在进程中使用文件来传输数据，只不过FIFO类型文件同时具有管道的特性。在数据读出时，FIFO管道中同时清除数据，并且“先进先出”。下面的例子演示了使用 FIFO 进行 IPC 的过程： 

write_fifo.c ：

```c
 1 #include<stdio.h>
 2 #include<stdlib.h>   // exit
 3 #include<fcntl.h>    // O_WRONLY
 4 #include<sys/stat.h>
 5 #include<time.h>     // time
 6 
 7 int main()
 8 {
 9     int fd;
10     int n, i;
11     char buf[1024];
12     time_t tp;
13 
14     printf("I am %d process.\n", getpid()); // 说明进程ID
15     
16     if((fd = open("fifo1", O_WRONLY)) < 0) // 以写打开一个FIFO 
17     {
18         perror("Open FIFO Failed");
19         exit(1);
20     }
21 
22     for(i=0; i<10; ++i)
23     {
24         time(&tp);  // 取系统当前时间
25         n=sprintf(buf,"Process %d's time is %s",getpid(),ctime(&tp));
26         printf("Send message: %s", buf); // 打印
27         if(write(fd, buf, n+1) < 0)  // 写入到FIFO中
28         {
29             perror("Write FIFO Failed");
30             close(fd);
31             exit(1);
32         }
33         sleep(1);  // 休眠1秒
34     }
35 
36     close(fd);  // 关闭FIFO文件
37     return 0;
38 }

```

read_fifo.c :

```c
 1 #include<stdio.h>
 2 #include<stdlib.h>
 3 #include<errno.h>
 4 #include<fcntl.h>
 5 #include<sys/stat.h>
 6 
 7 int main()
 8 {
 9     int fd;
10     int len;
11     char buf[1024];
12 
13     if(mkfifo("fifo1", 0666) < 0 && errno!=EEXIST) // 创建FIFO管道
14         perror("Create FIFO Failed");
15 
16     if((fd = open("fifo1", O_RDONLY)) < 0)  // 以读打开FIFO
17     {
18         perror("Open FIFO Failed");
19         exit(1);
20     }
21     
22     while((len = read(fd, buf, 1024)) > 0) // 读取FIFO管道
23         printf("Read message: %s", buf);
24 
25     close(fd);  // 关闭FIFO文件
26     return 0;
27 }
```



在两个终端里用 gcc 分别编译运行上面两个文件，可以看到输出结果如下： 

```c
1 [cheesezh@localhost]$ ./write_fifo 
 2 I am 5954 process.
 3 Send message: Process 5954's time is Mon Apr 20 12:37:28 2015
 4 Send message: Process 5954's time is Mon Apr 20 12:37:29 2015
 5 Send message: Process 5954's time is Mon Apr 20 12:37:30 2015
 6 Send message: Process 5954's time is Mon Apr 20 12:37:31 2015
 7 Send message: Process 5954's time is Mon Apr 20 12:37:32 2015
 8 Send message: Process 5954's time is Mon Apr 20 12:37:33 2015
 9 Send message: Process 5954's time is Mon Apr 20 12:37:34 2015
10 Send message: Process 5954's time is Mon Apr 20 12:37:35 2015
11 Send message: Process 5954's time is Mon Apr 20 12:37:36 2015
12 Send message: Process 5954's time is Mon Apr 20 12:37:37 2015
```

```c
 1 [cheesezh@localhost]$ ./read_fifo 
 2 Read message: Process 5954's time is Mon Apr 20 12:37:28 2015
 3 Read message: Process 5954's time is Mon Apr 20 12:37:29 2015
 4 Read message: Process 5954's time is Mon Apr 20 12:37:30 2015
 5 Read message: Process 5954's time is Mon Apr 20 12:37:31 2015
 6 Read message: Process 5954's time is Mon Apr 20 12:37:32 2015
 7 Read message: Process 5954's time is Mon Apr 20 12:37:33 2015
 8 Read message: Process 5954's time is Mon Apr 20 12:37:34 2015
 9 Read message: Process 5954's time is Mon Apr 20 12:37:35 2015
10 Read message: Process 5954's time is Mon Apr 20 12:37:36 2015
11 Read message: Process 5954's time is Mon Apr 20 12:37:37 2015

```

上述例子可以扩展成 客户进程—服务器进程 通信的实例，write_fifo的作用类似于客户端，可以打开多个客户端向一个服务器发送请求信息，read_fifo类似于服务器，它适时监控着FIFO的读端，当有数据时，读出并进行处理，但是有一个关键的问题是，每一个客户端必须预先知道服务器提供的FIFO接口，下图显示了这种安排：

![](./assets/1.5.png)





### 2.3 消息队列

消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标识。

**特点：**

1. 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。
2. 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。

3. 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。



### 2.4 信号量

信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。

**特点：**

1. 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。
2. 信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。

3. 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。

4. 支持信号量组。



最简单的信号量是只能取 0 和 1 的变量，这也是信号量最常见的一种形式，叫做二值信号量（Binary Semaphore）。而可以取多个正整数的信号量被称为通用信号量。

Linux 下的信号量函数都是在通用的信号量数组上进行操作，而不是在一个单一的二值信号量上进行操作。



### 2.5 共享内存

共享内存（Shared Memory），指两个或多个进程共享一个给定的存储区。

**特点：**

1. 共享内存是最快的一种 IPC，因为进程是直接对内存进行存取。
2. 因为多个进程可以同时操作，所以需要进行同步。

3. 信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问



### 2.6 信号

**1. 概念：**

 　　1）信号是在软件层次上对中断机制的一种模拟，是一种异步通信方式

 　　2）信号可以直接进行用户空间进程和内核进程之间的交互，内核进程也可以利用它来通知用户空间进程发生了哪些系统事件。

 　　3）如果该进程当前并未处于执行态，则该信号就由内核保存起来，直到该进程恢复执行再传递给它；如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被 取消时才被传递给进程。

 **2.用户进程对信号的响应方式：**

 　　1）忽略信号：对信号不做任何处理，但是有两个信号不能忽略：即SIGKILL及SIGSTOP。

 　　2）捕捉信号：定义信号处理函数，当信号发生时，执行相应的处理函数。

 　　3）执行缺省操作：Linux对每种信号都规定了默认操作

 

### 2.7 套接字(socket)

面说到的进程间的通信，所通信的进程都是在同一台计算机上的，而使用socket进行通信的进程可以是同一台计算机的进程，也是可以是通过网络连接起来的不同计算机上的进程。通常我们使用socket进行网络编程，这里将会简单地讲述如何使用``socket``进行简单的网络编程。 

套接字的特性由3个属性确定，它们分别是：**域、类型和协议**。 

1. **套接字的域**

  它指定套接字通信中使用的网络介质，最常见的套接字域是AF_INET，它指的是Internet网络。当客户使用套接字进行跨网络的连接时，它就需要用到服务器计算机的IP地址和端口来指定一台联网机器上的某个特定服务，所以在使用socket作为通信的终点，服务器应用程序必须在开始通信之前绑定一个端口，服务器在指定的端口等待客户的连接。另一个域AF_UNIX表示UNIX文件系统，它就是文件输入/输出，而它的地址就是文件名。



2. **套接字类型**

  因特网提供了两种通信机制：流（stream）和数据报（datagram），因而套接字的类型也就分为流套接字和数据报套接字。这里主要讲流套接字。

- **流套接字**由类型SOCK_STREAM指定，它们是在AF_INET域中通过**TCP/IP**连接实现，同时也是AF_UNIX中常用的套接字类型。流套接字提供的是一个有序、可靠、双向字节流的连接，因此发送的数据可以确保不会丢失、重复或乱序到达，而且它还有一定的出错后重新发送的机制。
- **数据报套接字**由类型SOCK_DGRAM指定，它不需要建立连接和维持一个连接，它们在AF_INET中通常是通过**UDP/IP协议**实现的。它对可以发送的数据的长度有限制，数据报作为一个单独的网络消息被传输,它可能会丢失、复制或错乱到达，UDP不是一个可靠的协议，但是它的速度比较高，因为它并一需要总是要建立和维持一个连接。





### 2.7 总结

1. **管道：**速度慢，容量有限，只有父子进程能通讯    
2. **FIFO：**任何进程间都能通讯，但速度慢    
3. **消息队列：**容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题    
4. **信号量：**不能传递复杂消息，只能用来同步    
5. **共享内存区：**能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存



# 4 线程同步的方式

### 4.1 linux线程同步机制

[博客](https://blog.csdn.net/a987073381/article/details/52029070)

##### 4.1.1 互斥量

互斥量本质上说是一把锁，在访问共享资源前对互斥量进行加锁，在访问完成后释放互斥量。



##### 4.1.2 读写锁

一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁。 



##### 4.1.3 条件变量 

互斥量用于上锁，条件变量则用于等待，并且条件变量总是需要与互斥量一起使用， 条件变量本身是由互斥量保护的，线程在改变条件变量之前必须首先锁住互斥量。 



##### 4.1.4 **信号量** 

信号量实际上是一个非负的整数计数器，用来实现对公共资源的控制。在公共资源增加的时候，信号量就增加；公共资源减少的时候，信号量就减少；只有当信号量的值大于0的时候，才能访问信号量所代表的公共资源。 



##### 4.1.5 自旋锁 

自旋锁与互斥量类似，但它不是通过休眠使进程阻塞，而是在获取锁之前一直处于忙等（自旋）阻塞状态。自旋锁可以用于以下情况：锁被持有的时间短，而且线程并不希望在重新调度上花费太多的成本。 



##### 4.1.6 屏障 

屏障是指用户可以协调多个线程并行工作的同步机制。屏障允许每个线程等待，直到所有的合作线程都到达某一点，然后从改点继续执行。
还记pthread_join函数吗？在子线程退出之前，主线程要一直等待。pthread_join函数就是一种屏障，它允许一个线程等待，直到另一个线程退出。屏障允许任意数量的线程等待，直到所有的线程完成处理工作，而线程不需要退出。所有线程达到屏障后可以接着工作。
如果我们要让主线程在所有工作线程完成之后再做某项任务，一般把屏障计数值设为工作线程数加1，主线程也作为其中一个候选线程。



### 4.2 java线程同步机制

[博客](https://blog.csdn.net/qq_22847457/article/details/89430008)

##### 4.2.1 synchronized关键字  

由于java的每个对象都有一个内置锁，当用此关键字修饰方法时， 内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态。

>注： synchronized关键字也可以修饰静态方法，此时如果调用该静态方法，将会锁住整个类。
>
>sychronized修饰的方法可以是静态方法和非静态方法，但是不能是抽象类的抽象方法，也不能是接口中的接口方法。



##### 4.2.2 wait和notify 

wait():使一个线程处于等待状态，并且释放所持有的对象的lock。

sleep():使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要捕捉InterruptedException异常。
notify():唤醒一个处于等待状态的线程，注意的是在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且不是按优先级。
Allnotity():唤醒所有处入等待状态的线程，注意并不是给所有唤醒线程一个对象的锁，而是让它们竞争。


##### 4.2.3 volatile

1. volatile关键字为域变量的访问提供了一种免锁机制
2. 使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新
3. 因此每次使用该域就要重新计算，而不是使用寄存器中的值 
4. volatile不会提供任何原子操作，它也不能用来修饰final类型的变量 



##### 4.2.4 ReentrantLock

在JavaSE5.0中新增了一个java.util.concurrent包来支持同步。 ReentrantLock类是可重入、互斥、实现了Lock接口的锁，它与使用synchronized方法和快具有相同的基本行为和语义，并且扩展了其能力。

 ReenreantLock类的常用方法有：

- ReentrantLock() : 创建一个ReentrantLock实例 
- lock() : 获得锁 
- unlock() : 释放锁 

> 注：ReentrantLock()还有一个可以创建公平锁的构造方法，但由于能大幅度降低程序运行效率，不推荐使用  



##### 4.2.5 ThreadLocal

如果使用ThreadLocal管理变量，则每一个使用该变量的线程都获得该变量的副本，副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响。 

 ThreadLocal 类的常用方法:

- ThreadLocal() : 创建一个线程本地变量 
- get() : 返回此线程局部变量的当前线程副本中的值 
- initialValue() : 返回此线程局部变量的当前线程的"初始值" 
- set(T value) : 将此线程局部变量的当前线程副本中的值设置为value

**采用以"空间换时间"的方法**



##### 4.2.6 使用阻塞队列 

前面5种同步方式都是在底层实现的线程同步，但是我们在实际开发当中，应当尽量远离底层结构。  

常用LinkedBlockingQueue() 。



##### 4.2.7 AtomicInteger 

使用原子变量实现线程同步 

原子操作就是指将读取变量值、修改变量值、保存变量值看成一个整体来操作即-这几种行为要么同时完成，要么都不完成。

在java的util.concurrent.atomic包中提供了创建了原子类型变量的工具类，使用该类可以简化线程同步。其中AtomicInteger 表可以用原子方式更新int的值，可用在应用程序中(如以原子方式增加的计数器)，但不能用于替换Integer；可扩展Number，允许那些处理机遇数字类的工具和实用工具进行统一访问。




# 5 进程同步有哪几种机制 

原子操作、信号量机制、自旋锁、管程、会合、分布式系统 

### 5.1 信号量机制

什么是信号量？信号量（semaphore）的数据结构为一个值和一个指针，指针指向等待该信号量的下一个进程。信号量的值与相应资源的使用情况有关。

- 当它的值大于0时，表示当前可用资源的数量；
- 当它的值小于0时，其绝对值表示等待使用该资源的进程个数。

一个信号量只能置一次初值，以后只能对之进行p操作或v操作。 由此也可以看到，信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点。  



### 5.2 原子操作

[博客](https://www.cnblogs.com/fanzhidongyzby/p/3654855.html)

C语言语句“count++;”在未经编译器优化时生成的汇编代码为：

![](./assets/1.16.jpg)

当操作系统内存在多个进程同时执行这段代码时，就可能带来并发问题。 

假设count变量初始值为0。进程1执行完“mov eax, [count]”后，寄存器eax内保存了count的值0。此时，进程2被调度执行，抢占了进程1的CPU的控制权。进程2执行“count++;”的汇编代码，将累加后的count值1写回到内存。然后，进程1再次被调度执行，CPU控制权回到进程1。进程1接着执行，计算count的累加值仍为1，写回到内存。虽然进程1和进程2执行了两次“count++;”操作，但是count实际的内存值为1，而不是2！ 



##### 5.2.1 单处理器原子操作

解决这个问题的方法是，将“count++;”语句翻译为单指令操作。 

![](./assets/1.17.jpg)





##### 5.2.2 多处理器原子操作

但是在多处理器的环境下，例如SMP架构，这个结论不再成立。我们知道“inc [count]”指令的执行过程分为三步：

1）从内存将count的数据读取到cpu。

2）累加读取的值。

3）将修改的值写回count内存。

于是Intel x86指令集提供了指令前缀lock用于锁定前端串行总线（FSB），保证了指令执行时不会受到其他处理器的干扰。 

![](./assets/1.18.jpg)

使用lock指令前缀后，处理器间对count内存的并发访问（读/写）被禁止，从而保证了指令的原子性。 





### 5.3 自旋锁

基于原子操作，nginx实现了一个自旋锁。自旋锁是为了保护共享资源提出的一种锁机制。 自旋锁是一种非睡眠锁。调用者申请的资源如果被占用，即自旋锁被已经被别的执行单元保持，则调用者一直循环在那里看是否该自旋锁的保持着已经释放了锁，自旋锁是一种比较低级的保护数据结构和代码片段的原始方式，可能会引起以下两个问题;   （1）死锁   （2）过多地占用CPU资源  



**应用场景：**

   自旋锁主要是为多处理器操作系统而设置的，他要解决的共享资源保护场景就是进程使用锁的时间非常短（如果锁的使用时间很久，自旋锁不合适，因为会占用大量的CPU资源）。  

   大部分情况下Nginx的worker进程最好都不要进入睡眠状态，因为它非常繁忙，在这个进程的epoll上可能有十万甚至百万的TCP连接等待着处理，进程一旦睡眠后必须等待其他事件的唤醒，这中间及其频繁的进程间切换带来的负载消耗可能无法让用户接受。  



### 5.4 管程

[博客](https://www.cnblogs.com/yongh/p/9294838.html)

在信号量机制中，每个要访问临界资源的进程都必须自备同步的PV操作，大量分散的同步操作会给系统管理带来麻烦，且容易因为同步操作不当而导致系统死锁。于是便产生了一种新的进程同步工具——**管程（Monitors）**。

**管程（Monitors）：**是一个资源管理模块，其中包含了共享资源的数据结构，以及由对该共享数据结构实施操作的一组过程（方法）所组成的资源管理程序。

管程中包含**条件变量**，用于管理进程的阻塞和唤醒。其形式为 condition x；对它的操作仅有wait和signal。

- **x.wait**：正在调用管程的进程因 x 条件需要被阻塞或挂起，则调用 x.wait 将自己插入到 x 条件的等待队列上，并释放管程，直到 x 条件变化。此时其它进程可以使用该管程。
- **x.signal**：正在调用管程的进程发现 x 条件发生了变化，则调用 x.signal，重新启动一个因 x 条件而阻塞或挂起的进程。（与信号量的signal不同，没有s:=s+1的操作）

 

**java中的管程：**

Java 采用的是管程技术，synchronized 关键字及 wait()、notify()、notifyAll() 这三个方法都是管程的组成部分。而**管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程**。但是**管程利用OOP的封装特性解决了信号量在工程实践上的复杂性问题**，因此java采用管理机制。 



**总结：**

1. 管程相当于把对临界资源的操作封装了起来，当进程要对资源进行操作时，只要调用管程中的方法就可以了，而不用进程自己担心同步和互斥的问题，管程的内部有自己的一套机制进行同步与互斥。
2. 管程中每次只允许一个进程进入管程。
3. 当调用管程的进程因为某原因阻塞或者挂起时，把这个原因定义为一个条件变量x。
4. x.wait操作就是把自己放到一个队列上，这个队列上的进程都是因为x原因而阻塞的。
5. x.signal操作就是让在x阻塞队列上的一个进程重新启动。

> **相对形象的比喻**：假如一个管程叫ATM（取款机），其包含两个方法：存款和取款，不同的人代表不同的进程，但是ATM只允许一个人在一个时间段中进行操作，当一个人在使用时，其他的人只能wait。此外，一个人如果使用的时间太长也不行，所以需要一个条件变量来约束他。
>
> 比如一个人在操作ATM时突然接电话了，没法继续操作，把这个原因记为x，执行x.wait，让他离开ATM机，去接电话的队列中等待。等到打完电话，即调用了x.signal后，他就可以继续操作ATM了（一般令正在操作ATM的人操作完后，他才能重新进去）。

 



### 5.5 会合

管程比PV操作要高级一些，但是和PV操作等价，只适合与单处理器系统及具有公共内存的多处理器系统。 

是适合分布式系统的同步机制。



### 5.6 分布式系统

适合分布式系统的同步机制。





# 6 线程生命周期状态

![](./assets/1.6.png)





### 6.1 新建

当程序使用new关键字创建了一个线程之后，该线程就处于新建状态，此时仅由 JVM 为其分配内存，并初始化其成员变量的值

 

### 6.2 就绪

当线程对象调用了 start()方法之后，该线程处于就绪状态。Java 虚拟机会为其创建方法调用栈和程序计数器，等待调度运行.



### 6.3 运行 Running

如果处于就绪状态的线程获得了CPU资源，就开始执行run方法的线程执行体，则该线程处于运行状态。run方法的那里呢？其实run也是在native线程中。



### 6.4 阻塞 Blocked

阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况大概三种：

1. **等待阻塞：**运行的线程执行wait()方法，JVM会把该线程放入等待池中。(wait会释放持有的锁)
2. **同步阻塞：**运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池中。
3. **其他阻塞：**运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。（注意,sleep是不会释放持有的锁）。

**线程睡眠：**Thread.sleep(long millis)方法，使线程转到阻塞状态。millis参数设定睡眠的时间，以毫秒为单位。当睡眠结束后，就转为就绪（Runnable）状态。sleep()平台移植性好。
 **线程等待：**Object类中的wait()方法，导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 唤醒方法。这个两个唤醒方法也是Object类中的方法，行为等价于调用 wait(0) 一样。唤醒线程后，就转为就绪（Runnable）状态。
 **线程让步：**Thread.yield() 方法，暂停当前正在执行的线程对象，把执行机会让给相同或者更高优先级的线程。
 **线程加入：**join()方法，等待其他线程终止。在当前线程中调用另一个线程的join()方法，则当前线程转入阻塞状态，直到另一个进程运行结束，当前线程再由阻塞转为就绪状态。
 **线程I/O：**线程执行某些IO操作，因为等待相关的资源而进入了阻塞状态。比如说监听system.in，但是尚且没有收到键盘的输入，则进入阻塞状态。
 **线程唤醒：**Object类中的notify()方法，唤醒在此对象监视器上等待的单个线程。如果所有线程都在此对象上等待，则会选择唤醒其中一个线程，选择是任意性的，并在对实现做出决定时发生。类似的方法还有一个notifyAll()，唤醒在此对象监视器上等待的所有线程。



### 6.5 死亡 Dead

线程会以以下三种方式之一结束，结束后就处于死亡状态:

1. run()方法执行完成，线程正常结束。
2. 线程抛出一个未捕获的Exception或Error。
3. 直接调用该线程的stop()方法来结束该线程——该方法容易导致死锁，通常不推荐使用。





## 7 进程生命周期

就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源；

运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数；

阻塞状态： 进程等待某种条件，在条件满足之前无法执行；

![](./assets/1.7.jpg)



# 8 **什么是死锁？死锁产生的条件？** 

[博客](https://blog.csdn.net/wljliujuan/article/details/79614019)

### 8.1 死锁的概念

在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲，就是两个或多个进程无限期的阻塞、相互等待的一种状态。



### 8.2 资源的类型

##### 8.2.1  可重用资源和消耗性资源

**1.可重用资源（永久性资源）**

可被多个进程多次使用，如所有硬件。

- 只能分配给一个进程使用，不允许多个进程共享。
- 进程在对可重用资源的使用时，须按照请求资源、使用资源、释放资源这样的顺序。
- 系统中每一类可重用资源中的单元数目是相对固定的，进程在运行期间，既不能创建，也不能删除。



**2.消耗性资源（临时性资源）**

又称临时性资源，是由进程在运行期间动态的创建和消耗的。

- 消耗性资源在进程运行期间是可以不断变化的，有时可能为0。
- 进程在运行过程中，可以不断地创造可消耗性资源的单元，将它们放入该资源类的缓冲区中，以增加该资源类的单元数目。
- 进程在运行过程中，可以请求若干个可消耗性资源单元，用于进程自己消耗，不再将它们返回给该资源类中。

可消耗资源通常是由生产者进程创建，由消费者进程消耗。最典型的可消耗资源是用于进程间通信的消息。 



##### 8.2.2 可抢占资源和不可抢占资源

**1.可抢占资源**

可抢占资源指某进程在获得这类资源后，该资源可以再被其他进程或系统抢占。对于这类资源是不会引起死锁的。

> CPU 和主存均属于可抢占性资源。



**2.不可抢占资源**

一旦系统把某资源分配给该进程后，就不能将它强行收回，只能在进程用完后自行释放。

> 磁带机、打印机等属于不可抢占性资源。



### 8.3 产生死锁的原因

##### 8.3.1 竞争不可抢占资源引起死锁

如：共享文件时引起死锁
系统中拥有两个进程P1和P2，它们都准备写两个文件F1和F2。而这两者都属于可重用和不可抢占性资源。如果进程P1在打开F1的同时，P2进程打开F2文件，当P1想打开F2时由于F2已结被占用而阻塞，当P2想打开1时由于F1已结被占用而阻塞，此时就会无线等待下去，形成死锁。 



##### 8.3.2 竞争可消耗资源引起死锁

如：进程通信时引起死锁
系统中拥有三个进程P1、P2和P3，m1、m2、m3是3可消耗资源。进程P1一方面产生消息m1，将其发送给P2，另一方面要从P3接收消息m3。而进程P2一方面产生消息m2，将其发送给P3，另一方面要从P1接收消息m1。类似的，进程P3一方面产生消息m3，将其发送给P1，另一方面要从P2接收消息m2。
如果三个进程都先发送自己产生的消息后接收别人发来的消息，则可以顺利的运行下去不会产生死锁，但要是三个进程都先接收别人的消息而不产生消息则会永远等待下去，产生死锁。



##### 8.3.3 **进程推进顺序不当引起死锁** 

例如，并发进程 P1、P2分别保持了资源R1、R2，而进程P1申请资源R2，进程P2申请资源R1时，两者都会因为所需资源被占用而阻塞。  



### 8.4 死锁产生的四个必要条件

产生死锁的必要条件：

- 互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。
- 请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放。
- 不剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放。
- 环路等待条件：在发生死锁时，必然存在一个进程--资源的环形链。





### 8.5 处理死锁的方法

### 8.5.1 预防死锁

通过设置某些限制条件，去破坏产生死锁的四个必要条件中的一个或几个条件，来防止死锁的发生。







### 8.5.2 避免死锁

在资源的动态分配过程中，用某种方法去防止系统进入不安全状态，从而避免死锁的发生。

##### 8.5.2.1 常用避免死锁的方法

有序资源分配法
银行家算法





##### 8.5.2.2 常用避免死锁的技术

加锁顺序
加锁时限
死锁检测



### 8.5.3 检测死锁

允许系统在运行过程中发生死锁，但可设置检测机构及时检测死锁的发生，并采取适当措施加以清除。



### 8.5.4 解除死锁

当检测出死锁后，便采取适当措施将进程从死锁状态中解脱出来。











# 9 页式管理、段式管理和段页式管理(内存管理) 

[博客](https://blog.csdn.net/smilesundream/article/details/70148878)

内存管理方式主要分为：页式管理、段式管理和段页式管理。 

基本存储分配方式：

![](./assets/1.14.png)



### 9.1 页式管理

 页式管理的基本原理是将各进程的虚拟空间划分为若干个长度相等的页。把内存空间按页的大小划分为片或者页面，然后把页式虚拟地址与内存地址建立一一对应的页表，并用相应的硬件地址转换机构来解决离散地址变换问题。页式管理采用请求调页和预调页技术来实现内外存存储器的统一管理。

-  优点：没有外碎片，每个内碎片不超过页的大小。
-  缺点：程序全部装入内存，要求有相应的硬件支持，如地址变换机构缺页中断的产生和选择淘汰页面等都要求有相应的硬件支持。增加了机器成本和系统开销。





### 9.2 段式管理

 段式管理的基本思想是把程序按内容或过程函数关系分成段，每段有自己的名字。一个用户作业或者进程所包含的段对应一个二维线性虚拟空间，也就是一个二维虚拟存储器。段式管理程序以段为单位分配内存，然后通过地址映射机构把段式虚拟地址转换为实际内存物理地址。

-  优点：可以分别编写和编译，可以针对不同类型的段采取不同的保护，可以按段为单位来进行共享，包括通过动态链接进行代码共享。
-  缺点：会产生碎片。



### 9.3  段页式管理

 段页式管理，系统必须为每个作业或者进程建立一张段表以管理内存分配与释放、缺段处理等。另外由于一个段又被划分为若干个页，每个段必须建立一张页表以把段中的虚页变换为内存中的实际页面。显然与页式管理时相同，页表也要有相应的实现缺页中断处理和页面保护等功能的表项。

 段页式管理是段式管理和页式管理相结合而成，具有两者的优点。

由于管理软件的增加，复杂性和开销也增加。另外需要的硬件以及占用的内存也有所增加，使得执行速度下降。





段式存储和页式存储的区别：

- 目的不同：分页是由于系统管理的需要而不是用户的需要，它是信息的物理单位；分段的目的是为了能更好地满足用户的需要，它是信息的逻辑单位，它含有一组其意义相对完整的信息；
- 大小不同：页的大小固定且由系统决定，而段的长度却不固定，由其所完成的功能决定；

- 地址空间不同： 段向用户提供二维地址空间；页向用户提供的是一维地址空间；

- 信息共享：段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制；

- 内存碎片：页式存储管理的优点是没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）；而段式管理的优点是没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）。



# 10 操作系统中进程调度策略















# 11 内存&虚拟内存 

### 11.1 内存 

[博客](https://www.cnblogs.com/jmsjh/p/7811601.html)

##### 11.1.1 为什么需要内存

程序和数据平常存储在硬盘等存储器上，不管你开机或关机了，它们都是存在的，不会丢失。硬盘可以存储的东西很多，但其传输数据的速度较慢。所以需要运行程序或打开数据时，这些数据必须从硬盘等存储器上先传到另一种容量小但速度快得多的存储器，之后才送入CPU进行执行处理。这中间的存储器就是内存。 

![](./assets/1.8.png)



**读一个磁盘扇区的流程：**

> 1. CPU 将相关的命令和地址，通过系统总线和IO总线传递给磁盘，发起一个磁盘读。
> 2. 磁盘控制器将相关的地址解析，并通过IO总线与内存总线将数据传给内存。
> 3. 第2步完成之后，磁盘控制器向CPU发送一个中断信号。(学电子的同学应该很清楚中断是什么)。这时CPU就知道了，数据已经发送到内存了。

第二步磁盘操作很慢，但是在第一步CPU发出信号后。但是第二步和第三步时，CPU根本不参与。第二步很耗时，所以CPU在第一步发出信号后，就切换到另一个线程。所以此时的CPU依旧没有闲着。而在第三步时，通过中断，硬盘主动发信号给CPU，你需要的数据已经发送到内存了，然后此时它可以将线程再切换回来，接着执行这个该线程的任务。 



**应用程序：**

对于一个应用/进程而言，它都应该有一个入口。(虽然不一定需要我们直接写`main`函数)。入口函数内部就是我们的任务代码，任务代码执行完了这个应用/进程也就结束了。这个很好理解，比如测试工程师写的一个测试case。跑完了这个任务就结束了。

但是 有些程序，比如一个  app，你打开了这个app。不做任何操作。这个界面会一直存在，也不会消失。

所以这个app进程的入口main来讲，其实是这样的。

```c
int main(){
    boolean flag  = true;
    while (flag){
        //我们执行任务的代码
    }
    return 0;
}
```



##### 11.2 局部性原理

* 时间局部性(temporal locality):被引用过一次的存储器位置的内容在未来会被多次引用。
* 空间局部性(spatial locality):如果一个存储器位置的内容被引用，那么它附近的位置也很大概率会被引用。



### 11.2 虚拟内存

[博客1](https://www.cnblogs.com/jmsjh/p/8017202.html)

[博客2](https://www.cnblogs.com/logo-fox/p/10843348.html)

维基百科上的解释：

虚拟内存不只是“用磁盘空间来扩展物理内存”的意思——这只是扩充内存级别以使其包含硬盘驱动器而已。把内存扩展到磁盘只是使用虚拟内存技术的一个结果，它的作用也可以通过覆盖或者把处于不活动状态的程序以及它们的数据全部交换到磁盘上等方式来实现。对虚拟内存的定义是基于对地址空间的重定义的，即把地址空间定义为“连续的虚拟内存地址”，以借此“欺骗”程序，使它们以为自己正在使用一大块的“连续”地址。 



##### 11.1 为什么需要虚拟内存

解决了三个使用连续物理内存时的问题：

- **问题1：进程地址空间不隔离。**由于程序都是直接访问物理内存，所以恶意程序可以随意修改别的进程的内存数据，以达到破坏的目的。有些非恶意的，但是有bug的程序也可能不小心修改了其它程序的内存数据，就会导致其它程序的运行出现异常。这种情况对用户来说是无法容忍的，因为用户希望使用计算机的时候，其中一个任务失败了，至少不能影响其它的任务。
- **问题2：内存使用效率低。**在A和B都运行的情况下，如果用户又运行了程序C，而程序C需要20M大小的内存才能运行，而此时系统只剩下8M的空间可供使用，所以此时系统必须在已运行的程序中选择一个将该程序的数据暂时拷贝到硬盘上，释放出部分空间来供程序C使用，然后再将程序C的数据全部装入内存中运行。可以想象得到，在这个过程中，有大量的数据在装入装出，导致效率十分低下。
- **问题3：程序运行的地址不确定。**当内存中的剩余空间可以满足程序C的要求后，操作系统会在剩余空间中随机分配一段连续的20M大小的空间给程序C使用，因为是随机分配的，所以程序运行的地址是不确定的。



概念：虚拟内存也是一种缓存思想,虚拟内存将主存看成是一个磁盘的高速缓存，主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据。虚拟内存的地址和磁盘的地址之间建立影射关系。磁盘上活动的数组内容被缓存在主存中。

虚拟内存（VM）系统将虚拟内存分割成称为大小固定的虚拟页（Virtual Page,VP），每个虚拟页的大小为固定字节。同样的，物理内存被分割为物理页（Physical Page,PP）,大小也为固定字节（物理页也称作页帧，page frame）。

![](./assets/1.9.png)



在任意时刻，虚拟页面都分为三个不相交的部分：

- **未分配的(Unallocated)**：VM 系统还未分配（或者创建）的页，未分配的页没有任何数据和它们关联，因此不占用任何内存/磁盘空间。
- **缓存的(Cached)**：当前已缓存在物理内存中的已分配页。
- **未缓存的(UnCached)**：该页已经映射到磁盘上了，但是还没缓存在物理内存中。

> 其中**未分配的VP**不占用任何的实际物理空间，这点要理解。如果程序每个VP都映射着实际的PP。无论如何也对应不上的。并且也完全没必要一一映射,下图中可以看到，地址空间内有大量的空白。毕竟程序不可能实际使用那么大的地址空间。 

![](./assets/1.10.png)



##### 11.2 页表

系统必须得有办法判定某个虚拟页是否缓存在主存的某个地方。这具体可分为两种情况。

- 已经在主存中，就需要判断出该虚拟页存在于哪个物理页中。
- 不在主存中，那么系统必须判断虚拟页存放在磁盘的哪个位置，并且在物理主存中选择一个牺牲页，并将该虚拟页从磁盘复制到 主存，替换这个牺牲页。

这些功能由软硬件联合提供，包括操作系统，CPU中的**内存管理单元（Memory Management Unit,MMU）**和一个存放在物理内存中叫**页表（page table）**的数据结构，页表将虚拟页映射到物理页。每次地址翻译硬件将一个虚拟地址转换成物理地址时都会读取页表。

![](./assets/1.11.png)

上图展示了一个页表的基本结构，页表就是一个**页表条目（Page Table Entry,PTE）**的数组。虚拟地址的每个页在页表中都有一个对应的PTE。在这里我们假设每个 PTE 是由一个有效位（Valid bit）和一个 n 位地址字段组成的。有效位表明了该虚拟页当前是否被缓存在 主存 中。

- 有效位为 1，则主存缓存了该虚拟页。地址字段就表示主存中相应的物理页的起始位置。
- 有效位为 0，则地址字段的null表示这个虚拟页还未被分配，否则该地址就指向该虚拟页在磁盘上的起始位置。

> 命中和缺页：
>
> 当CPU想要读取包含在某个虚拟页的内容时，如果该页已经缓存在主存中，也就是**页命中**。perfect,很完美。但是如果该页没有缓存在主存中，则我们称之为**缺页(page fault)** 



**理所当然的，每个进程都有一个独立的页表和一个独立的虚拟地址空间**。





##### 11.3 共享页面

比如每个C程序都要调用的 `stdio`这个库，不可能为每个进程都添加一份库，内存中只有一份`stdio`库的内容，供每个使用该库的进程共享。 

![](./assets/1.12.jpg)

如上图所示: 第一个进程的的页表将 VP2 映射到 某个物理页面。而第二个进程同样将它的 VP2 映射到 该物理页面。所以该物理页面都被两个进程共享了。 

所以说**虚拟内存简化了共享机制** .



##### 11.4 内存保护

大家知道，C语言中存在指针，可以直接进行内存操作。因为有了虚拟内存，所以我们的指针操作也不会访问到其他进程的区域，但是哪怕是对于自己的地址空间，很多内存区域也应该是禁止访问的，这不仅包括kernel的区域，也包括自己的只读代码段。那么虚拟内存就提供了这样的一种内存保护工具。 

**地址翻译机制**可以使用一种自然的方式来提供内存的访问控制。PTE 上添加一些额外的控制位来添加权限。每次 CPU 生成一个地址时，地址翻译硬件都会读一个 PTE 。 

![](./assets/1.13.png)



##### 11.5 段 和 页

我们明白了页，页是操作系统为了管理主存方便而划分的，对用户不可见。但是思考这种情况，假设一个页的大小是1M。但是某个程序数据加起来也就0.5M，所以在内存和磁盘进行页交换明显的浪费内存了。所以还一种划分方式是**分段**。上面那个例子，我将该段划分为0.5M，在内存和磁盘之间交换，这样就避免了浪费。

段是信息的逻辑单元，是根据用户需求而灵活划分的，所以大小不固定，对用户是可见的，提供的是二维地址空间。



##### 11.6 swap分区的作用

熟悉linux的同学，应该知道linux有一个swap分区。Swap空间的作用可简单描述为：当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间中的信息被临时保存到Swap空间中，等到那些程序要运行时，再从Swap中恢复保存的数据到内存中。系统总是在物理内存不够时，才进行Swap交换。

> 你电脑打开了一个音乐播放器，但是也没播放歌曲，然后你几天不关机，也一直没关闭这个音乐播放器，随着运行的程序越来越多，内存快不够用了，所以操作系统就选择将这个音乐播放器的内存状态(包括堆栈状态等)都写到磁盘上的swap区进行保存。这样就腾出来一部分内存供其他需要运行的程序使用。你啥时候想听歌了，就找到了这个音乐播放器程序操作。此时，  系统会从磁盘中的swap区重新读取该音乐播放器的相关信息，送回内存接着运行。

在window下也有类作用的硬盘空间，属于对用户不可见的匿名磁盘空间(在C盘)。



> **按照字面意思，swap交换区也可以称为虚拟内存**
>
> 硬盘上的swap交换区，起到了扩大内存的作用。所以从某些意义上来讲，swap区也可以叫做虚拟内存，但是**这个虚拟内存是字面意思**。和我们本文当中站在计算机系统的角度来解释的虚拟内存不是一个概念.



> linux环境下叫做swap分区，window下这块区域没叫做swap分区，就直接按照字面意思叫做"虚拟内存"了。



